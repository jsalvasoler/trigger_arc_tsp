{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90cba5f3",
   "metadata": {},
   "source": [
    "# Data set exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5cbdd4",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad37d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parse_instance_file(filepath):\n",
    "    \"\"\"\n",
    "    Parses a single instance file and returns its structured data.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The full path to the instance file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the parsed data with keys:\n",
    "              'N': Number of nodes\n",
    "              'A': Number of arcs\n",
    "              'R': Number of relationships\n",
    "              'arcs': A list of dictionaries, each representing an arc with keys:\n",
    "                      'index', 'from_node', 'to_node', 'cost'\n",
    "              'relationships': A list of dictionaries, each representing a relationship with keys:\n",
    "                               'index', 'from_trigger', 'to_trigger', 'trigger_arc_index',\n",
    "                               'from_target', 'to_target', 'target_arc_index', 'new_target_arc_cost'\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'N': 0,\n",
    "        'A': 0,\n",
    "        'R': 0,\n",
    "        'arcs': [],\n",
    "        'relationships': []\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            # Parse the first line: |N| |A| |R|\n",
    "            n_a_r = list(map(int, lines[0].strip().split()))\n",
    "            data['N'] = n_a_r[0]\n",
    "            data['A'] = n_a_r[1]\n",
    "            data['R'] = n_a_r[2]\n",
    "\n",
    "            current_line_idx = 1\n",
    "\n",
    "            # Parse arcs\n",
    "            for _ in range(data['A']):\n",
    "                arc_parts = list(map(float, lines[current_line_idx].strip().split()))\n",
    "                data['arcs'].append({\n",
    "                    'index': int(arc_parts[0]),\n",
    "                    'from_node': int(arc_parts[1]),\n",
    "                    'to_node': int(arc_parts[2]),\n",
    "                    'cost': arc_parts[3]\n",
    "                })\n",
    "                current_line_idx += 1\n",
    "\n",
    "            # Parse relationships\n",
    "            for _ in range(data['R']):\n",
    "                rel_parts = list(map(float, lines[current_line_idx].strip().split()))\n",
    "                data['relationships'].append({\n",
    "                    'index': int(rel_parts[0]),\n",
    "                    'from_trigger': int(rel_parts[1]),\n",
    "                    'to_trigger': int(rel_parts[2]),\n",
    "                    'trigger_arc_index': int(rel_parts[3]),\n",
    "                    'from_target': int(rel_parts[4]),\n",
    "                    'to_target': int(rel_parts[5]),\n",
    "                    'target_arc_index': int(rel_parts[6]),\n",
    "                    'new_target_arc_cost': rel_parts[7]\n",
    "                })\n",
    "                current_line_idx += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing file {filepath}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def explore_datasets(base_folder_path=\"../instances/\", vocal=False):\n",
    "    \"\"\"\n",
    "    Explores all instance files within subdirectories of the specified base folder.\n",
    "    The structure is expected to be base_folder_path/dataset_name/instance_file.txt\n",
    "\n",
    "    Args:\n",
    "        base_folder_path (str): The path to the main 'instances' folder.\n",
    "\n",
    "    Returns:\n",
    "        dict: A nested dictionary where the first level keys are dataset names,\n",
    "              and the second level keys are instance filenames, holding the parsed data.\n",
    "              Example: {'dataset_name_1': {'instance1.txt': {...}, 'instance2.txt': {...}}, ...}\n",
    "    \"\"\"\n",
    "    all_parsed_datasets = {}\n",
    "    if not os.path.isdir(base_folder_path):\n",
    "        print(f\"Error: Base folder '{base_folder_path}' not found.\")\n",
    "        return all_parsed_datasets\n",
    "\n",
    "    # Iterate through each dataset folder inside the base_folder_path\n",
    "    for dataset_name in os.listdir(base_folder_path):\n",
    "        dataset_folder_path = os.path.join(base_folder_path, dataset_name)\n",
    "\n",
    "        # Check if it's actually a directory\n",
    "        if os.path.isdir(dataset_folder_path):\n",
    "            print(f\"\\n--- Exploring Dataset: {dataset_name} ---\")\n",
    "            parsed_instances_in_dataset = {}\n",
    "\n",
    "            # Iterate through files within the dataset folder\n",
    "            for filename in os.listdir(dataset_folder_path):\n",
    "                if filename.endswith(\".txt\"):\n",
    "                    filepath = os.path.join(dataset_folder_path, filename)\n",
    "                    if vocal:\n",
    "                        print(f\"  Parsing instance: {filename}\")\n",
    "                    parsed_data = parse_instance_file(filepath)\n",
    "                    parsed_instances_in_dataset[filename] = parsed_data\n",
    "\n",
    "                    # --- Example Exploration for this instance ---\n",
    "                    if parsed_data and vocal:\n",
    "                        print(f\"    Nodes (N): {parsed_data['N']}\")\n",
    "                        print(f\"    Arcs (A): {parsed_data['A']}\")\n",
    "                        print(f\"    Relationships (R): {parsed_data['R']}\")\n",
    "\n",
    "                        if parsed_data['arcs']:\n",
    "                            print(f\"    First 3 arcs (if available):\")\n",
    "                            for i, arc in enumerate(parsed_data['arcs'][:3]):\n",
    "                                print(f\"      Arc {i}: From {arc['from_node']} to {arc['to_node']}, Cost {arc['cost']}\")\n",
    "\n",
    "                        if parsed_data['relationships']:\n",
    "                            print(f\"    First 3 relationships (if available):\")\n",
    "                            for i, rel in enumerate(parsed_data['relationships'][:3]):\n",
    "                                print(f\"      Rel {i}: Trigger Arc ({rel['from_trigger']}, {rel['to_trigger']}, Index {rel['trigger_arc_index']}), \"\n",
    "                                      f\"Target Arc ({rel['from_target']}, {rel['to_target']}, Index {rel['target_arc_index']}), \"\n",
    "                                      f\"New Cost {rel['new_target_arc_cost']}\")\n",
    "                    elif vocal:\n",
    "                        print(f\"    No data parsed for {filename}\")\n",
    "\n",
    "            all_parsed_datasets[dataset_name] = parsed_instances_in_dataset\n",
    "\n",
    "    return all_parsed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f197151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exploring Dataset: instances_generic ---\n",
      "\n",
      "--- Exploring Dataset: instances_release_2 ---\n",
      "\n",
      "--- Exploring Dataset: instances_release_1 ---\n"
     ]
    }
   ],
   "source": [
    "all_datasets_data = explore_datasets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "# Assume parse_instance_file and explore_datasets functions are defined as before\n",
    "# (They are not included here for brevity, but assume they are in the same script)\n",
    "\n",
    "def summarize_parsed_data(all_datasets_data):\n",
    "    \"\"\"\n",
    "    Generates a comprehensive summary of the parsed datasets, comparing them\n",
    "    based on the number of instances, size of instances, and cost metrics.\n",
    "\n",
    "    Args:\n",
    "        all_datasets_data (dict): The nested dictionary returned by explore_datasets.\n",
    "                                  Format: {'dataset_name': {'instance_name': parsed_data, ...}, ...}\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"                 DATASET PARSING SUMMARY AND COMPARISON\")\n",
    "    print(\"=\"*120)\n",
    "\n",
    "    if not all_datasets_data:\n",
    "        print(\"No datasets were parsed or found.\")\n",
    "        return\n",
    "\n",
    "    total_datasets = len(all_datasets_data)\n",
    "    total_instances_across_all = sum(len(instances) for instances in all_datasets_data.values())\n",
    "\n",
    "    print(f\"\\nOverall Summary:\")\n",
    "    print(f\"----------------\")\n",
    "    print(f\"Total number of datasets found: {total_datasets}\")\n",
    "    print(f\"Total number of instances parsed across all datasets: {total_instances_across_all}\")\n",
    "\n",
    "    print(\"\\nDetailed Dataset Comparison:\")\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "    dataset_summaries = {}\n",
    "\n",
    "    for dataset_name, instances_data in all_datasets_data.items():\n",
    "        num_instances = len(instances_data)\n",
    "        nodes_values = []\n",
    "        arcs_values = []\n",
    "        relationships_values = []\n",
    "        avg_arc_costs = []\n",
    "        avg_relation_costs = []\n",
    "        relationships_changing_cost_percentages = []\n",
    "        valid_instances_count = 0\n",
    "\n",
    "        for instance_name, data in instances_data.items():\n",
    "            if data and all(k in data for k in ['N', 'A', 'R', 'arcs', 'relationships']):\n",
    "                nodes_values.append(data['N'])\n",
    "                arcs_values.append(data['A'])\n",
    "                relationships_values.append(data['R'])\n",
    "\n",
    "                # Calculate average arc cost for this instance\n",
    "                if data['arcs']:\n",
    "                    total_arc_cost = sum(arc['cost'] for arc in data['arcs'])\n",
    "                    avg_arc_costs.append(total_arc_cost / len(data['arcs']))\n",
    "                else:\n",
    "                    avg_arc_costs.append(0) # Or a suitable default/N/A\n",
    "\n",
    "                # Calculate average relationship new target arc cost for this instance\n",
    "                if data['relationships']:\n",
    "                    total_rel_cost = sum(rel['new_target_arc_cost'] for rel in data['relationships'])\n",
    "                    avg_relation_costs.append(total_rel_cost / len(data['relationships']))\n",
    "\n",
    "                    # Calculate percentage of relationships where cost changes\n",
    "                    original_arc_costs = {arc['index']: arc['cost'] for arc in data['arcs']}\n",
    "                    relationships_changing_cost = 0\n",
    "                    for rel in data['relationships']:\n",
    "                        target_arc_idx = rel['target_arc_index']\n",
    "                        new_cost = rel['new_target_arc_cost']\n",
    "                        original_cost = original_arc_costs.get(target_arc_idx)\n",
    "\n",
    "                        # Check if original_cost exists and if new_cost is different\n",
    "                        if original_cost is not None and new_cost != original_cost:\n",
    "                            relationships_changing_cost += 1\n",
    "                    \n",
    "                    if len(data['relationships']) > 0:\n",
    "                        change_percentage = (relationships_changing_cost / len(data['relationships'])) * 100\n",
    "                        relationships_changing_cost_percentages.append(change_percentage)\n",
    "                    else:\n",
    "                        relationships_changing_cost_percentages.append(0) # No relationships means 0% change\n",
    "                else:\n",
    "                    avg_relation_costs.append(0) # Or a suitable default/N/A\n",
    "                    relationships_changing_cost_percentages.append(0)\n",
    "\n",
    "                valid_instances_count += 1\n",
    "            else:\n",
    "                print(f\"  Warning: Skipping incomplete data for {dataset_name}/{instance_name}\")\n",
    "\n",
    "        dataset_summaries[dataset_name] = {\n",
    "            'num_instances': num_instances,\n",
    "            'valid_instances': valid_instances_count,\n",
    "            'nodes_stats': {\n",
    "                'min': min(nodes_values) if nodes_values else 'N/A',\n",
    "                'max': max(nodes_values) if nodes_values else 'N/A',\n",
    "                'avg': sum(nodes_values) / len(nodes_values) if nodes_values else 'N/A',\n",
    "            },\n",
    "            'arcs_stats': {\n",
    "                'min': min(arcs_values) if arcs_values else 'N/A',\n",
    "                'max': max(arcs_values) if arcs_values else 'N/A',\n",
    "                'avg': sum(arcs_values) / len(arcs_values) if arcs_values else 'N/A',\n",
    "            },\n",
    "            'relationships_stats': {\n",
    "                'min': min(relationships_values) if relationships_values else 'N/A',\n",
    "                'max': max(relationships_values) if relationships_values else 'N/A',\n",
    "                'avg': sum(relationships_values) / len(relationships_values) if relationships_values else 'N/A',\n",
    "            },\n",
    "            'avg_instance_arc_cost_stats': { # Average of average arc costs per instance\n",
    "                'min': min(avg_arc_costs) if avg_arc_costs else 'N/A',\n",
    "                'max': max(avg_arc_costs) if avg_arc_costs else 'N/A',\n",
    "                'avg': sum(avg_arc_costs) / len(avg_arc_costs) if avg_arc_costs else 'N/A',\n",
    "            },\n",
    "            'avg_instance_relation_cost_stats': { # Average of average relation costs per instance\n",
    "                'min': min(avg_relation_costs) if avg_relation_costs else 'N/A',\n",
    "                'max': max(avg_relation_costs) if avg_relation_costs else 'N/A',\n",
    "                'avg': sum(avg_relation_costs) / len(avg_relation_costs) if avg_relation_costs else 'N/A',\n",
    "            },\n",
    "            'rel_cost_change_pct_stats': { # Average percentage of relationships changing cost\n",
    "                'min': min(relationships_changing_cost_percentages) if relationships_changing_cost_percentages else 'N/A',\n",
    "                'max': max(relationships_changing_cost_percentages) if relationships_changing_cost_percentages else 'N/A',\n",
    "                'avg': sum(relationships_changing_cost_percentages) / len(relationships_changing_cost_percentages) if relationships_changing_cost_percentages else 'N/A',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Print formatted table header\n",
    "    # Adjusted column widths for new metrics\n",
    "    print(f\"{'Dataset':<20} | {'# Inst.':<9} | {'Nodes (Min/Avg/Max)':<25} | {'Arcs (Min/Avg/Max)':<23} | {'Rels (Min/Avg/Max)':<23} | {'Avg Arc Cost (Avg)':<18} | {'Avg Rel Cost (Avg)':<20} | {'Rel Cost % Change (Avg)':<25}\")\n",
    "    print(\"-\" * 185) # Adjust line length\n",
    "\n",
    "    for dataset_name, summary in dataset_summaries.items():\n",
    "        nodes_str = f\"{summary['nodes_stats']['min']}/{summary['nodes_stats']['avg']:.0f}/{summary['nodes_stats']['max']}\" if isinstance(summary['nodes_stats']['avg'], float) else 'N/A'\n",
    "        arcs_str = f\"{summary['arcs_stats']['min']}/{summary['arcs_stats']['avg']:.0f}/{summary['arcs_stats']['max']}\" if isinstance(summary['arcs_stats']['avg'], float) else 'N/A'\n",
    "        rels_str = f\"{summary['relationships_stats']['min']}/{summary['relationships_stats']['avg']:.0f}/{summary['relationships_stats']['max']}\" if isinstance(summary['relationships_stats']['avg'], float) else 'N/A'\n",
    "\n",
    "        avg_arc_cost_str = f\"{summary['avg_instance_arc_cost_stats']['avg']:.2f}\" if isinstance(summary['avg_instance_arc_cost_stats']['avg'], float) else 'N/A'\n",
    "        avg_rel_cost_str = f\"{summary['avg_instance_relation_cost_stats']['avg']:.2f}\" if isinstance(summary['avg_instance_relation_cost_stats']['avg'], float) else 'N/A'\n",
    "        rel_cost_change_pct_str = f\"{summary['rel_cost_change_pct_stats']['avg']:.2f}%\" if isinstance(summary['rel_cost_change_pct_stats']['avg'], float) else 'N/A'\n",
    "\n",
    "\n",
    "        print(f\"{dataset_name:<20} | {summary['num_instances']:<9} | {nodes_str:<25} | {arcs_str:<23} | {rels_str:<23} | {avg_arc_cost_str:<18} | {avg_rel_cost_str:<20} | {rel_cost_change_pct_str:<25}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"End of Summary\")\n",
    "    print(\"=\"*120)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b913608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "                 DATASET PARSING SUMMARY AND COMPARISON\n",
      "========================================================================================================================\n",
      "\n",
      "Overall Summary:\n",
      "----------------\n",
      "Total number of datasets found: 3\n",
      "Total number of instances parsed across all datasets: 235\n",
      "\n",
      "Detailed Dataset Comparison:\n",
      "----------------------------\n",
      "Dataset              | # Inst.   | Nodes (Min/Avg/Max)       | Arcs (Min/Avg/Max)      | Rels (Min/Avg/Max)      | Avg Arc Cost (Avg) | Avg Rel Cost (Avg)   | Rel Cost % Change (Avg)  \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "instances_generic    | 180       | 10/18/25                  | 90/320/600              | 100/2092/10000          | 2587.19            | 3042.15              | 100.00%                  \n",
      "instances_release_2  | 34        | 18/68/142                 | 90/580/1562             | 1144/47834/208020       | 1.00               | 1.08                 | 100.00%                  \n",
      "instances_release_1  | 21        | 20/40/60                  | 200/1267/2700           | 1732/556903/4527944     | 6.29               | 6.30                 | 99.88%                   \n",
      "\n",
      "========================================================================================================================\n",
      "End of Summary\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "summarize_parsed_data(all_datasets_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
